Allows easy regularization of outputs to prevent overfitting, yielding probabilities as prediction results.

Logistic Regression models does not get effected to predict output probabilities on removal of variables uncorrelated to the output or multi-collinear variables.

Logistic regressionâ€™s greatest disadvantage is fails to solve non-linear problems and it underperforms when there are multiple or non-linear decision boundaries. It fails to capture more complex relationships.

Logistic Regression is used when that the data is linearly separable or classifiable and the outcome is Binary

MLE (Maximum Likelihood Estimation) is an iterative procedure, meaning that it starts with a guess as to the best weight for each predictor variable (that is, each coefficient in the model) and then adjusts these coefficients repeatedly until there is no additional improvement in the ability to predict the value of the outcome variable (either 0 or 1) for each case.

The target is binary
IID observations
No (or little) Multicollinearity
linearity of independent variables(only continuous variables) and logit(log odds)
typically requires a large sample size.  A general guideline is that you need at minimum of 10 cases with the least frequent outcome for each independent variable in your model.
There is no influential values (extreme values or outliers) in the continuous predictors
Independent errors
