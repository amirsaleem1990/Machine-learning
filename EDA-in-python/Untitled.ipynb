{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def new_line():\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "def plot_numerical_columns(col_name):\n",
    "    df[col_name].plot(figsize=(13,8));\n",
    "    plt.title(col_name, size=18);\n",
    "    plt.axhline(y=df[col_name].mean(), color='red');\n",
    "    plt.axhline(y=df[col_name].median(), color='green');\n",
    "    plt.legend(['Actual', 'Mean', 'Median']);\n",
    "    plt.show()\n",
    "    \n",
    "    df[col_name].sort_values().reset_index(drop=True).plot(figsize=(13,8));\n",
    "    plt.title(col_name+\" (SORTED)\", size=18);\n",
    "    plt.axhline(y=df[col_name].mean(), color='red');\n",
    "    plt.axhline(y=df[col_name].median(), color='green');\n",
    "    plt.legend(['Actual', 'Mean', 'Median']);\n",
    "    plt.show()\n",
    "\n",
    "    df[col_name].plot(kind=\"box\", figsize=(13,8))\n",
    "    plt.title(col_name, size=18);\n",
    "    plt.xlabel(\"\");\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def data_shape():\n",
    "    return f\"The Data have:\\n\\t{df.shape[0]} rows\\n\\t{df.shape[1]} columns\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "The Data have:\n",
      "\t2803 rows\n",
      "\t1383 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", date_parser=True)\n",
    "new_line()\n",
    "print(data_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Columns types distribution:\n",
      "\n",
      "float64    1378\n",
      "object        3\n",
      "int64         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "print(f\"Columns types distribution:\\n\\n{df.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 33 (out of 1383, [2%]) columns that contains 1 or more NA\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "a = df.isna().sum().where(lambda x:x>0).dropna()\n",
    "print(f\"There are {len(a)} (out of {df.shape[1]}, [{round(len(a)/df.shape[1]*100)}%]) columns that contains 1 or more NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 31 columns that are all Missing values, so we droped those.\n",
      "Now The Data have:\n",
      "\t2803 rows\n",
      "\t1352 columns\n",
      "\n",
      "\n",
      "Dropped columns names:\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "a = a.sort_values()/len(df)*100\n",
    "if (a == 100).sum():\n",
    "    df.drop(columns=a[a==100].index, inplace=True)\n",
    "    print(f\"There are {(a == 100).sum()} columns that are all Missing values, so we droped those.\\nNow {data_shape()}\\n\\nDropped columns names:\")\n",
    "#     for i in a[a==100].index:\n",
    "#         print(\"\\t\",i)\n",
    "    a = a[a != 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "NA columns data type Distribution:\n",
      "\n",
      "float64    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "print(f\"NA columns data type Distribution:\\n\\n{df[a.index].dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "NaN Ratio (0-100)\n",
      "\n",
      "min_call_Duration_sqrt    0.035676\n",
      "min_call_Duration_log     0.035676\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "if a.size:\n",
    "    print(f\"NaN Ratio (0-100)\\n\\n{a}\")\n",
    "else:\n",
    "    print(\"Now There is no NaN value in our Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "if a.size:\n",
    "    new_line()\n",
    "#     is ko uncomment karna h\n",
    "#     ans = input(\"Are you need to remove some columns?[y|n]\")\n",
    "    ans = \"n\" \n",
    "    if ans == \"y\":\n",
    "        to_remove = input(\"Please Enter columns names delimated by $\\neg:Columns_1$Columns_2\").split(\"$\")\n",
    "        df.drop(columns=to_remove, inplace=True)\n",
    "        print(f\"Now {data_shape()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTING missing values??????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 157 variables That have only one unique value, so we drop those.\n",
      "\n",
      "Now The Data have:\n",
      "\t2803 rows\n",
      "\t1195 columns\n",
      "\n",
      "\n",
      "Those columns names in order:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "only_one_unique_value = df.nunique().where(lambda x:x == 1).dropna()\n",
    "if only_one_unique_value.size:\n",
    "    new_line()\n",
    "    df.drop(columns=only_one_unique_value.index, inplace=True)\n",
    "    print(f\"There are {only_one_unique_value.size} variables That have only one unique value, so we drop those.\\n\\nNow {data_shape()}\\n\\nThose columns names in order:\\n\")\n",
    "#     for i in only_one_unique_value.index.sort_values():\n",
    "#         print(i)\n",
    "del only_one_unique_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 1 column/s that have all unique values, so no value repeatation, we droped those columns.\n",
      "\n",
      "Now The Data have:\n",
      "\t2803 rows\n",
      "\t1194 columns\n",
      "\n",
      "Those column/s name/s are:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_values_are_unique = df.apply(lambda x:x.is_unique).where(lambda x:x==True).dropna()\n",
    "if all_values_are_unique.size:\n",
    "    new_line()\n",
    "    df.drop(columns=all_values_are_unique.index, inplace=True)\n",
    "    print(f\"There are {all_values_are_unique.size} column/s that have all unique values, so no value repeatation, we droped those columns.\\n\\nNow {data_shape()}\\nThose column/s name/s are:\\n\")\n",
    "#     for i in f.index:\n",
    "#         print(\"\\t\", i)\n",
    "del all_values_are_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.head().select_dtypes(\"number\").columns\n",
    "numerical_summary = df[numerical_cols].agg([min,max, np.mean, 'count', pd.Series.nunique]).T\n",
    "numerical_summary.columns = numerical_summary.columns.str.capitalize()\n",
    "numerical_summary['Outliers_count'] = df[numerical_cols].apply(lambda x:((x - x.mean())/x.std()).abs() > 3).sum()\n",
    "numerical_summary['Outliers_Ratio(0-100)'] = round(numerical_summary.Outliers_count / len(df) * 100, 2)\n",
    "del numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 383 numeric columns that have minimum value is less than 0, is This ok?\n",
      "\n",
      "Those columns names (in order):\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_is_nagetive = numerical_summary.Min[numerical_summary.Min < 0]\n",
    "if min_is_nagetive.size:\n",
    "    new_line()\n",
    "    print(f\"There are {min_is_nagetive.size} numeric columns that have minimum value is less than 0, is This ok?\\n\\nThose columns names (in order):\\n\\n\")\n",
    "#     for i in min_is_nagetive.index.sort_values():\n",
    "#         print(i)\n",
    "del min_is_nagetive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 729 numeric columns that have minimum value is 0, is This ok?\n",
      "\n",
      "Those columns names (in order):\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_is_0 = numerical_summary.Min[numerical_summary.Min == 0]\n",
    "if min_is_0.size:\n",
    "    new_line()\n",
    "    print(f\"There are {min_is_0.size} numeric columns that have minimum value is 0, is This ok?\\n\\nThose columns names (in order):\\n\\n\")\n",
    "#     for i in min_is_0.index.sort_values():\n",
    "#         print(i)\n",
    "del min_is_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "new_line()    \n",
    "# for col_ in df.select_dtypes(\"number\").columns:\n",
    "#     plot_numerical_columns(col_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Numerical Data Summary:\n",
      "Notes:\n",
      "\t1-Count:          non-NA/null observations in the Series\n",
      "\t2-Outliers_count: Values that are more far than |3| std from its mean\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "print(\"Numerical Data Summary:\\nNotes:\\n\\t1-Count:          non-NA/null observations in the Series\\n\\t2-Outliers_count: Values that are more far than |3| std from its mean\\n\\n\")\n",
    "# print(numerical_summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catagorical Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4 and the array at index 2 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-a9c4d28afae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcatagorical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcatagorical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                     df[catagorical_cols].apply(lambda x:x.value_counts().where(lambda x:x==1).dropna().size)])#, index=['Most frequent value Ratio', 'Least frequent value Ratio', 'Values occured only once Ratio']).T\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcatagorical_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         return _list_of_series_to_arrays(\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         )\n\u001b[1;32m    533\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_of_series_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0maligned_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4 and the array at index 2 has size 2"
     ]
    }
   ],
   "source": [
    "catagorical_cols = df.head().select_dtypes(exclude=\"number\").columns\n",
    "catagorical_summary = pd.DataFrame([df[catagorical_cols].apply(lambda x:x.value_counts().iloc[0]/x.count()*100),\n",
    "                                    df[catagorical_cols].apply(lambda x:x.value_counts().iloc[-1]/x.count()*100),\n",
    "                                    df[catagorical_cols].agg(['count', pd.Series.nunique]),\n",
    "                                    df[catagorical_cols].apply(lambda x:x.value_counts().where(lambda x:x==1).dropna().size)])#, index=['Most frequent value Ratio', 'Least frequent value Ratio', 'Values occured only once Ratio']).T\n",
    "catagorical_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2803</td>\n",
       "      <td>2803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nunique</th>\n",
       "      <td>1142</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         min_timestamp  brand\n",
       "count             2803   2803\n",
       "nunique           1142     44"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
