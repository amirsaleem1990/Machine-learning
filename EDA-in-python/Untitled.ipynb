{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def new_line():\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "def plot_numerical_columns(col_name):\n",
    "    df[col_name].plot(figsize=(13,8));\n",
    "    plt.title(col_name, size=18);\n",
    "    plt.axhline(y=df[col_name].mean(), color='red');\n",
    "    plt.axhline(y=df[col_name].median(), color='green');\n",
    "    plt.legend(['Actual', 'Mean', 'Median']);\n",
    "    plt.show()\n",
    "    \n",
    "    df[col_name].sort_values().reset_index(drop=True).plot(figsize=(13,8));\n",
    "    plt.title(col_name+\" (SORTED)\", size=18);\n",
    "    plt.axhline(y=df[col_name].mean(), color='red');\n",
    "    plt.axhline(y=df[col_name].median(), color='green');\n",
    "    plt.legend(['Actual', 'Mean', 'Median']);\n",
    "    plt.show()\n",
    "\n",
    "    df[col_name].plot(kind=\"box\", figsize=(13,8))\n",
    "    plt.title(col_name, size=18);\n",
    "    plt.xlabel(\"\");\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def data_shape():\n",
    "    return f\"The Data have:\\n\\t{df.shape[0]} rows\\n\\t{df.shape[1]} columns\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "The Data have:\n",
      "\t2803 rows\n",
      "\t1383 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\", date_parser=True)\n",
    "new_line()\n",
    "print(data_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Columns types distribution:\n",
      "\n",
      "float64    1378\n",
      "object        3\n",
      "int64         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "print(f\"Columns types distribution:\\n\\n{df.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 33 (out of 1383, [2%]) columns that contains 1 or more NA\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "a = df.isna().sum().where(lambda x:x>0).dropna()\n",
    "print(f\"There are {len(a)} (out of {df.shape[1]}, [{round(len(a)/df.shape[1]*100)}%]) columns that contains 1 or more NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 31 columns that are all Missing values, so we droped those.\n",
      "Now The Data have:\n",
      "\t2803 rows\n",
      "\t1352 columns\n",
      "\n",
      "\n",
      "Dropped columns names:\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "a = a.sort_values()/len(df)*100\n",
    "if (a == 100).sum():\n",
    "    df.drop(columns=a[a==100].index, inplace=True)\n",
    "    print(f\"There are {(a == 100).sum()} columns that are all Missing values, so we droped those.\\nNow {data_shape()}\\n\\nDropped columns names:\")\n",
    "#     for i in a[a==100].index:\n",
    "#         print(\"\\t\",i)\n",
    "    a = a[a != 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "NA columns data type Distribution:\n",
      "\n",
      "float64    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "print(f\"NA columns data type Distribution:\\n\\n{df[a.index].dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "NaN Ratio (0-100)\n",
      "\n",
      "min_call_Duration_sqrt    0.035676\n",
      "min_call_Duration_log     0.035676\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "if a.size:\n",
    "    print(f\"NaN Ratio (0-100)\\n\\n{a}\")\n",
    "else:\n",
    "    print(\"Now There is no NaN value in our Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "if a.size:\n",
    "    new_line()\n",
    "#     is ko uncomment karna h\n",
    "#     ans = input(\"Are you need to remove some columns?[y|n]\")\n",
    "    ans = \"n\" \n",
    "    if ans == \"y\":\n",
    "        to_remove = input(\"Please Enter columns names delimated by $\\neg:Columns_1$Columns_2\").split(\"$\")\n",
    "        df.drop(columns=to_remove, inplace=True)\n",
    "        print(f\"Now {data_shape()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTING missing values??????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 157 variables That have only one unique value, so we drop those.\n",
      "\n",
      "Now The Data have:\n",
      "\t2803 rows\n",
      "\t1195 columns\n",
      "\n",
      "\n",
      "Those columns names in order:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "only_one_unique_value = df.nunique().where(lambda x:x == 1).dropna()\n",
    "if only_one_unique_value.size:\n",
    "    new_line()\n",
    "    df.drop(columns=only_one_unique_value.index, inplace=True)\n",
    "    print(f\"There are {only_one_unique_value.size} variables That have only one unique value, so we drop those.\\n\\nNow {data_shape()}\\n\\nThose columns names in order:\\n\")\n",
    "#     for i in only_one_unique_value.index.sort_values():\n",
    "#         print(i)\n",
    "del only_one_unique_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 1 column/s that have all unique values, so no value repeatation, we droped those columns.\n",
      "\n",
      "Now The Data have:\n",
      "\t2803 rows\n",
      "\t1194 columns\n",
      "\n",
      "Those column/s name/s are:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_values_are_unique = df.apply(lambda x:x.is_unique).where(lambda x:x==True).dropna()\n",
    "if all_values_are_unique.size:\n",
    "    new_line()\n",
    "    df.drop(columns=all_values_are_unique.index, inplace=True)\n",
    "    print(f\"There are {all_values_are_unique.size} column/s that have all unique values, so no value repeatation, we droped those columns.\\n\\nNow {data_shape()}\\nThose column/s name/s are:\\n\")\n",
    "#     for i in f.index:\n",
    "#         print(\"\\t\", i)\n",
    "del all_values_are_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.head().select_dtypes(\"number\").columns\n",
    "numerical_summary = df[numerical_cols].agg([min,max, np.mean, 'count', pd.Series.nunique]).T\n",
    "numerical_summary.columns = numerical_summary.columns.str.capitalize()\n",
    "numerical_summary['Outliers_count'] = df[numerical_cols].apply(lambda x:((x - x.mean())/x.std()).abs() > 3).sum()\n",
    "numerical_summary['Outliers_Ratio(0-100)'] = round(numerical_summary.Outliers_count / len(df) * 100, 2)\n",
    "del numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 383 numeric columns that have minimum value is less than 0, is This ok?\n",
      "\n",
      "Those columns names (in order):\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_is_nagetive = numerical_summary.Min[numerical_summary.Min < 0]\n",
    "if min_is_nagetive.size:\n",
    "    new_line()\n",
    "    print(f\"There are {min_is_nagetive.size} numeric columns that have minimum value is less than 0, is This ok?\\n\\nThose columns names (in order):\\n\\n\")\n",
    "#     for i in min_is_nagetive.index.sort_values():\n",
    "#         print(i)\n",
    "del min_is_nagetive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "There are 729 numeric columns that have minimum value is 0, is This ok?\n",
      "\n",
      "Those columns names (in order):\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_is_0 = numerical_summary.Min[numerical_summary.Min == 0]\n",
    "if min_is_0.size:\n",
    "    new_line()\n",
    "    print(f\"There are {min_is_0.size} numeric columns that have minimum value is 0, is This ok?\\n\\nThose columns names (in order):\\n\\n\")\n",
    "#     for i in min_is_0.index.sort_values():\n",
    "#         print(i)\n",
    "del min_is_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "new_line()    \n",
    "# for col_ in df.select_dtypes(\"number\").columns:\n",
    "#     plot_numerical_columns(col_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Numerical Data Summary:\n",
      "Notes:\n",
      "\t1-Count:          non-NA/null observations in the Series\n",
      "\t2-Outliers_count: Values that are more far than |3| std from its mean\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_line()\n",
    "print(\"Numerical Data Summary:\\nNotes:\\n\\t1-Count:          non-NA/null observations in the Series\\n\\t2-Outliers_count: Values that are more far than |3| std from its mean\\n\\n\")\n",
    "# print(numerical_summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catagorical Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "date_columns = df.filter(regex=re.compile(\"date|time\", re.IGNORECASE)).select_dtypes(exclude=\"number\").columns.to_list()\n",
    "d = []\n",
    "for i in df.select_dtypes(\"O\").columns:\n",
    "    try:\n",
    "        df[i] = pd.to_datetime(df[i])\n",
    "        d.append(i)\n",
    "    except:\n",
    "        pass\n",
    "if d:\n",
    "    date_columns += d\n",
    "date_columns = list(set(date_columns))\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>nunique</th>\n",
       "      <th>Most frequent value Ratio</th>\n",
       "      <th>Least frequent value Ratio</th>\n",
       "      <th>Values occured only once Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>2803</td>\n",
       "      <td>44</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  nunique  Most frequent value Ratio  Least frequent value Ratio  \\\n",
       "brand   2803       44                       26.4                        0.04   \n",
       "\n",
       "       Values occured only once Ratio  \n",
       "brand                            0.36  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catagorical_cols = df.head().select_dtypes(exclude=\"number\").columns\n",
    "catagorical_cols = catagorical_cols.drop(date_columns)\n",
    "catagorical_summary = pd.DataFrame([\n",
    "    df[catagorical_cols].apply(lambda x:round(x.value_counts().iloc[0]/x.count()*100,2)),\n",
    "    df[catagorical_cols].apply(lambda x:round(x.value_counts().iloc[-1]/x.count()*100,2)),\n",
    "    df[catagorical_cols].apply(lambda x:round(x.value_counts().where(lambda x:x==1).dropna().size / x.count()*100, 2))\n",
    "], index=['Most frequent value Ratio', 'Least frequent value Ratio', 'Values occured only once Ratio']).T\n",
    "catagorical_summary = pd.merge(df[catagorical_cols].agg(['count', pd.Series.nunique]).T, catagorical_summary, left_index=True, right_index=True, how=\"outer\")\n",
    "catagorical_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for each catagorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020-09-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             min_timestamp\n",
       "min    1970-01-01 00:00:00\n",
       "max    2020-09-03 00:00:00\n",
       "count                 2803"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[date_columns].agg([min,max,'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
