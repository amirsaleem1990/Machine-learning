{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input(\"Am\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def new_line():\n",
        "    print(\"-------------------------\")\n",
        "\n",
        "def plot_numerical_columns(col_name):\n",
        "    df[col_name].plot(figsize=(13,8));\n",
        "    plt.title(col_name, size=18);\n",
        "    plt.axhline(y=df[col_name].mean(), color='red');\n",
        "    plt.axhline(y=df[col_name].median(), color='green');\n",
        "    plt.legend(['Actual', 'Mean', 'Median']);\n",
        "    plt.show()\n",
        "\n",
        "    df[col_name].sort_values().reset_index(drop=True).plot(figsize=(13,8));\n",
        "    plt.title(col_name+\" (SORTED)\", size=18);\n",
        "    plt.axhline(y=df[col_name].mean(), color='red');\n",
        "    plt.axhline(y=df[col_name].median(), color='green');\n",
        "    plt.legend(['Actual', 'Mean', 'Median']);\n",
        "    plt.show()\n",
        "\n",
        "    df[col_name].plot(kind=\"box\", figsize=(13,8))\n",
        "    plt.title(col_name, size=18);\n",
        "    plt.xlabel(\"\");\n",
        "    plt.show()\n",
        "\n",
        "def plot_date_columns(col_name):\n",
        "\n",
        "    df[col_name].plot(figsize=(15,7), grid=True);\n",
        "    plt.xlabel(\"Index\", size=14);\n",
        "    plt.ylabel(\"Date\", size=14);\n",
        "    plt.title(col_name + \" Graph\", size=18);\n",
        "    plt.show();\n",
        "\n",
        "    df[col_name].sort_values().reset_index(drop=True).plot(figsize=(15,7), grid=True);\n",
        "    plt.xlabel(\"Index (sorted)\", size=14);\n",
        "    plt.ylabel(\"Year\", size=14);\n",
        "    plt.title(col_name + \" Graph\", size=18);\n",
        "    plt.show();\n",
        "\n",
        "    (df[col_name].dt.year.value_counts(sort=False).sort_index() / len(df) * 100).plot(kind=\"bar\", figsize=(15,7), grid=True);\n",
        "    plt.xlabel(\"Year\", size=14);\n",
        "    plt.ylabel(\"Ratio (1-100)\", size=14);\n",
        "    plt.title(col_name + \" year Frequency Graph\", size=18);\n",
        "    plt.show();\n",
        "\n",
        "    (df[col_name].dt.month.value_counts().sort_index()/len(df) * 100).plot(kind=\"bar\", figsize=(15,7), grid=True);\n",
        "    plt.xlabel(\"Month\", size=14);\n",
        "    plt.ylabel(\"Ratio (1-100)\", size=14);\n",
        "    plt.title(col_name + \" month Frequency Graph\", size=18);\n",
        "    plt.show();\n",
        "\n",
        "    (df[col_name].dt.day.value_counts().sort_index()/len(df) * 100).plot(kind=\"bar\", figsize=(15,7), grid=True);\n",
        "    plt.xlabel(\"Day\", size=14);\n",
        "    plt.ylabel(\"Ratio (1-100)\", size=14);\n",
        "    plt.title(col_name + \" Day Frequency Graph\", size=18);\n",
        "    plt.show();\n",
        "\n",
        "def plot_catagorical_columns(cat_variable):\n",
        "    (df[cat_variable].value_counts() / len(df) * 100).plot.bar(figsize=(15,6), grid=True);\n",
        "    plt.title(cat_variable, size=18, color='r');\n",
        "    plt.xlabel(\"Catagory\", size=14, color='r');\n",
        "    plt.ylabel(\"Ratio (1-100)\", size=14, color='r');\n",
        "    plt.show()\n",
        "\n",
        "def data_shape():\n",
        "    return f\"The Data have:\\n\\t{df.shape[0]} rows\\n\\t{df.shape[1]} columns\\n\"\n",
        "#===\n",
        "# df = pd.read_csv(\"data.csv\", date_parser=True)\n",
        "df = pd.read_csv(\"df_only_selected_columns_using_PCA.csv\", date_parser=True)\n",
        "new_line()\n",
        "print(data_shape())\n",
        "#===\n",
        "new_line()\n",
        "print(f\"Columns types distribution:\\n\\n{df.dtypes.value_counts()}\")\n",
        "#---------------------------------------- NA\n",
        "a = df.isna().sum().where(lambda x:x>0).dropna()\n",
        "if a.size:\n",
        "    new_line()\n",
        "    print(f\"There are {len(a)} (out of {df.shape[1]}, [{round(len(a)/df.shape[1]*100)}%]) columns that contains 1 or more NA\")\n",
        "#===\n",
        "a = a.sort_values()/len(df)*100\n",
        "if (a == 100).sum():\n",
        "    new_line()\n",
        "    df.drop(columns=a[a==100].index, inplace=True)\n",
        "    print(f\"There are {(a == 100).sum()} columns that are all Missing values, so we droped those.\\nNow {data_shape()}\\n\\nDropped columns names:\")\n",
        "    for i in a[a==100].index:\n",
        "        print(\"\\t\",i)\n",
        "    a = a[a != 100]\n",
        "#===\n",
        "x = df[a.index].dtypes.value_counts()\n",
        "if x.size:\n",
        "    new_line()\n",
        "    print(f\"NA columns data type Distribution:\\n\\n{x}\")\n",
        "del x\n",
        "#===\n",
        "new_line()\n",
        "if a.size:\n",
        "    print(f\"NaN Ratio (0-100)\\n\\n{a}\")\n",
        "else:\n",
        "    print(\"Now There is no NaN value in our Data\")\n",
        "#===\n",
        "if a.size:\n",
        "    new_line()\n",
        "#     is ko uncomment karna h\n",
        "    # ans = input(\"Are you need to remove some columns?[y|n]\")\n",
        "    ans = \"n\"\n",
        "    if ans == \"y\":\n",
        "        to_remove = input(\"Please Enter columns names delimated by $\\neg:Columns_1$Columns_2\").split(\"$\")\n",
        "        df.drop(columns=to_remove, inplace=True)\n",
        "        print(f\"Now {data_shape()}\")\n",
        "#===\n",
        "# IMPUTING missing values??????????????\n",
        "#===\n",
        "# --------------------------------------------------------- Unique values\n",
        "only_one_unique_value = df.nunique().where(lambda x:x == 1).dropna()\n",
        "if only_one_unique_value.size:\n",
        "    new_line()\n",
        "    df.drop(columns=only_one_unique_value.index, inplace=True)\n",
        "    print(f\"There are {only_one_unique_value.size} variables That have only one unique value, so we drop those.\\n\\nNow {data_shape()}\\n\\nThose columns names in order:\\n\")\n",
        "    for i in only_one_unique_value.index.sort_values():\n",
        "        print(i)\n",
        "del only_one_unique_value\n",
        "# #===\n",
        "all_values_are_unique = df.apply(lambda x:x.is_unique).where(lambda x:x==True).dropna()\n",
        "if all_values_are_unique.size:\n",
        "    new_line()\n",
        "    df.drop(columns=all_values_are_unique.index, inplace=True)\n",
        "    print(f\"There are {all_values_are_unique.size} column/s that have all unique values, so no value repeatation, we droped those columns.\\n\\nNow {data_shape()}\\nThose column/s name/s are:\\n\")\n",
        "    for i in all_values_are_unique.index:\n",
        "        print(\"\\t\", i)\n",
        "del all_values_are_unique\n",
        "#===\n",
        "catagorical_columns = df.head().select_dtypes(\"O\").columns\n",
        "numerical_columns   = df.head().select_dtypes(\"number\").columns\n",
        "date_columns        = []\n",
        "\n",
        "for i in catagorical_columns:\n",
        "    try:\n",
        "        df[i] = pd.to_datetime(df[i])\n",
        "        date_columns.append(i)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "catagorical_columns = catagorical_columns.drop(date_columns)\n",
        "if date_columns:\n",
        "    date_columns = pd.Index(date_columns)\n",
        "#===\n",
        "if not catagorical_columns.append(numerical_columns).append(date_columns).is_unique:\n",
        "    new_line()\n",
        "    print(\"\\nSome column/s repated in > 1 dtypes\\n\")\n",
        "    dtypes = pd.DataFrame({\"Column\" : catagorical_columns.append(numerical_columns).append(date_columns),\n",
        "                \"dtype\" : ['O']*len(catagorical_columns) + ['Number']*len(numerical_columns) + ['Date']*len(date_columns)})\n",
        "    print(dtypes[dtypes.Column.isin(list(dtypes[dtypes.Column.duplicated()].Column.values))].to_string())\n",
        "#===\n",
        "x = df.columns.difference(\n",
        "    catagorical_columns.append(numerical_columns).append(date_columns)\n",
        "    )\n",
        "if x.size:\n",
        "    new_line()\n",
        "    print(\"Some columns not included in any existing catagory, those:\\n\")\n",
        "    for i in x:\n",
        "        print(f\"\\t<{i}, with dtype of <{df[i].dtype}>\")\n",
        "#===\n",
        "dtypes = pd.DataFrame({\"Column\" : catagorical_columns.append(numerical_columns).append(date_columns),\n",
        "            \"dtype\" : ['Object']*len(catagorical_columns) + ['Number']*len(numerical_columns) + ['Date']*len(date_columns)})\n",
        "dtypes.dtype.unique()\n",
        "#===\n",
        "# m = 0\n",
        "for row in dtypes.iterrows():\n",
        "    # m += 1\n",
        "    # if m == 3:\n",
        "        # break\n",
        "    column_name, type_ = row[1]\n",
        "    x = df[column_name]\n",
        "    print(f\"\\n\\n\\n=============================== {column_name} ===============================\\n\\n\")\n",
        "    print(f\"Column Type     : {type_}\")\n",
        "    if x.isna().all():\n",
        "        new_line()\n",
        "        df.drop(columns=column_name, inplace=True)\n",
        "        print(\"We dropped This column, because it is all Empty\")\n",
        "        continue\n",
        "    if type_ in [\"O\", \"Date\"]:\n",
        "        if x.is_unique:\n",
        "            new_line()\n",
        "            df.drop(columns=column_name, inplace=True)\n",
        "            print(f\"We dropped This column, because it's a {type_} columns, and it's all values are unique\")\n",
        "            continue\n",
        "    if x.nunique() == 1:\n",
        "        new_line()\n",
        "        df.drop(columns=column_name, inplace=True)\n",
        "        print(f\"We dropped This column, because There is only one unique value\")\n",
        "        continue\n",
        "\n",
        "    if type_ == \"Number\":\n",
        "\n",
        "        # f = x.describe()\n",
        "        # f['Nunique'] = x.nunique()\n",
        "        # f['Nunique ratio'] = f.loc[\"Nunique\"] / f.loc[\"count\"] * 100\n",
        "        # f['Outlies count'] = (((x - x.mean())/x.std()).abs() > 3).sum()\n",
        "        # f['Outlies ratio'] = f.loc[\"Outlies count\"] / f.loc[\"count\"] * 100\n",
        "        # f['Nagative values count'] = (x < 0).sum()\n",
        "        # f['Nagative values ratio'] = f['Nagative values count'] / f['count'] * 100\n",
        "\n",
        "        ff = [x.count(), x.isna().sum(), x.mean(), x.std(), x.min()]\n",
        "        ff += x.quantile([.25,.5,.75]).to_list()\n",
        "        ff += [x.max(), x.nunique(), (((x - x.mean())/x.std()).abs() > 3).sum(), (x < 0).sum()]\n",
        "\n",
        "        f = pd.DataFrame(ff, index=['Count', 'NA', 'Mean', 'Std', 'Min', '25%', '50%', '75%', 'Max', 'Nunique', 'Outlies', 'Nagetive'], columns=['Count'])\n",
        "        f['Ratio'] = f.Count / x.count() * 100\n",
        "        f.loc['Mean' : 'Max', 'Ratio'] = None\n",
        "\n",
        "        new_line()\n",
        "        print(f.round(2).to_string())\n",
        "        plot_numerical_columns(column_name)\n",
        "\n",
        "    elif type_ == \"Object\":\n",
        "        # f = x.describe()\n",
        "        # f = x.agg(['count', pd.Series.nunique])\n",
        "        # f['len'] = len(x)\n",
        "        # f['Na count'] = x.isna().sum()\n",
        "        # f['Na ratio'] = f['Na count'] / f['count'] * 100\n",
        "        # f['Most frequent'] = x.mode().values[0]\n",
        "        # f['Most frequent count'] = (x == f['Most frequent']).sum()\n",
        "        # f['Most frequent ratio'] = f['Most frequent count'] / f['count'] * 100\n",
        "        # f['Least frequent'] = x.value_counts().tail(1).index[0]\n",
        "        # f['Least frequent count'] = (x == f['Least frequent']).sum()\n",
        "        # f['Least frequent ratio'] = f['Least frequent count'] / f['count'] * 100\n",
        "        # f['Values occured only once count'] = x.value_counts().where(lambda x:x==1).dropna().size\n",
        "        # f['Values occured only once Ratio'] = f['Values occured only once count'] / x.count() * 100\n",
        "\n",
        "        l = x.count(), x.nunique(), len(x), x.isna().sum(), (x == x.mode().values[0]).sum(), (x == x.value_counts().tail(1).index[0]).sum(), x.value_counts().where(lambda x:x==1).dropna().size\n",
        "        f = pd.DataFrame(l, index=['Count', 'Nunique', 'Len', 'NA', 'Most frequent', 'Least frequent', 'Values occured only once'], columns=['Counts'])\n",
        "        f['Ratio'] = (f.Counts / x.count() * 100).round(4)\n",
        "        f.loc[['Count', 'Len'], 'Ratio'] = None\n",
        "\n",
        "        new_line()\n",
        "        print(f.to_string())\n",
        "\n",
        "\n",
        "        if x.str.lower().nunique() != x.nunique():\n",
        "            new_line()\n",
        "            print(f\"\\n\\nCase issue\\n\\tin orignal variable There are {x.nunique()} unique values\\n\\tin lower verstion there are   {x.str.lower().nunique()} unique values.\")\n",
        "\n",
        "        if x.str.strip().nunique() != x.nunique():\n",
        "            new_line()\n",
        "            print(f\"\\n\\nSpace issue\\n\\tin orignal variable There are {x.nunique()} unique values\\n\\tin striped verstion there are {x.str.strip().nunique()} unique values.\")\n",
        "\n",
        "        plot_catagorical_columns(column_name)\n",
        "\n",
        "    elif type == \"Date\":\n",
        "\n",
        "        new_line()\n",
        "        from dateutil import relativedelta\n",
        "        rd = relativedelta.relativedelta( pd.to_datetime(x.max()), pd.to_datetime(x.min()))\n",
        "        print(f\"Diffrenece between first and last date:\\n\\tYears : {rd.years}\\n\\tMonths: {rd.months}\\n\\tDays  : {rd.days}\\n\\n\")\n",
        "\n",
        "        # f = pd.Series({'Count' : x.count(),\n",
        "        #             'Nunique count' : x.nunique(),\n",
        "        #             'Nunique ratio' : x.nunique() / x.count() * 100,\n",
        "        #             'Most frequent value' : str(x.mode()[0]),\n",
        "        #             'Least frequent value' :  x.value_counts().tail(1).index[0]\n",
        "        #             })\n",
        "        # f['Most frequent count'] = (x == f['Most frequent value']).sum()\n",
        "        # f['Most frequent ratio'] = f['Most frequent count'] / f['Count'] * 100\n",
        "        # f['Least frequent count'] = (x == f['Least frequent value']).sum()\n",
        "        # f['Least frequent ratio'] = f['Least frequent count'] / f['Count'] * 100\n",
        "        # f['Values occured only once count'] = x.value_counts().where(lambda x:x==1).dropna().size\n",
        "        # f['Values occured only once Ratio'] = f['Values occured only once count'] / x.count() * 100\n",
        "\n",
        "        ff = x.count(), x.nunique(), (x == x.mode().values[0]).sum(), (x == x.value_counts().tail(1).index[0]).sum(), x.value_counts().where(lambda x:x==1).dropna().size\n",
        "        f = pd.DataFrame(ff, index=[\"Count\", 'Nunique', 'Most frequent values', 'Least frequent values', 'Values occured only once count'], columns=['Counts'])\n",
        "        f['Ratio'] = (f.Counts / x.count() * 100).round(4)\n",
        "\n",
        "        new_line()\n",
        "        print(f\"\\n{f.to_string()}\\n\\n\")\n",
        "\n",
        "\n",
        "        f = set(np.arange(x.dt.year.min(),x.dt.year.max()+1)).difference(\n",
        "            x.dt.year.unique())\n",
        "        if f:\n",
        "            new_line()\n",
        "            print(f\"These Years (in order) are missing:\\n\")\n",
        "            for i in f:\n",
        "                print(\"\\t\", i, end=\", \")\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "        f = set(np.arange(x.dt.month.min(),x.dt.month.max()+1)).difference(\n",
        "            x.dt.month.unique())\n",
        "        if f:\n",
        "            new_line()\n",
        "            print(f\"These Months (in order) are missing:\\n\")\n",
        "            for i in f:\n",
        "                print(\"\\t\", i, end=\", \")\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "        f = set(np.arange(x.dt.day.min(),x.dt.day.max()+1)).difference(\n",
        "            x.dt.day.unique())\n",
        "        if f:\n",
        "            new_line()\n",
        "            print(f\"These Days (in order) are missing:\\n\")\n",
        "            for i in f:\n",
        "                print(\"\\t\", i, end=\", \")\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "        new_line()\n",
        "        plot_date_columns(column_name)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}